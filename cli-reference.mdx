---
title: "CLI Reference"
description: "Comprehensive reference for the Thunder Compute CLI. Manage instances (create, delete), configure GPUs/CPUs, and handle files."
icon: "bolt"
iconType: "solid"
---

## Account Management

### Login

Authenticate the CLI, which provides a link to the [console](https://console.thundercompute.com/settings?tab=tokens) where you can generate an API token.

```
tnr login
```

Under the hood, this generates and saves an API token to `~/.thunder/token`. You can store a token file here to programmatically authenticate, or by setting the `TNR_API_TOKEN` environment variable in your shell.

### Logout

Log out of the CLI with:

```
tnr logout
```

This deletes the stored API token.

### API Token Management

- Generate/manage tokens in the [console](https://console.thundercompute.com/settings?tab=tokens)
- Tokens never expire but can be revoked
- Use unique tokens per device

## Managing Instances

### Create an Instance

Create a new Thunder Compute instance:

```
tnr create
```

This creates a new instance with default configuration and automatically assigns an instance ID.

<Note>
  Instance storage is ephemeral. Back up important data externally before you delete an instance. See [Using Ephemeral Storage](/guides/using-ephemeral-storage) for recommended workflows.
</Note>

#### CPU Configuration

Configure custom vCPU count:

```
tnr create --vcpus <vcpu_count>
```

Each vCPU comes with 8GB of RAM. For example, a 4 core instance has 32GB of RAM, and an 8 core instance has 64GB of RAM.

<Note>
  By default, 4 vCPUs and 32GB of memory are included with your instance. Additional vCPUs are
  billed hourly at the rates shown [here](https://www.thundercompute.com/pricing)
</Note>

#### GPU Configuration

Specify a GPU type:

```
tnr create --gpu <gpu_type>
```

Available GPU types:

- `t4`: NVIDIA T4 (16GB VRAM) - Best for most ML workloads
- `a100` (default): NVIDIA A100 (40GB VRAM) - For large models and high-performance computing
- `a100xl` : NVIDIA A100 (80GB VRAM) - For even larger models, the biggest and the best

You can use the `--num-gpus` flag to specify multiple GPU configurations:

```
tnr create --gpu <gpu_type> --num-gpus <n>
```

#### Template Configuration

Templates make it easy to quickly launch common AI tools. Your instance will already be configured with everything you need to get running to generate images, run an LLM, and more.

To use a template, add the `--template` flag when creating an instance:

```
tnr create --template <template_name>
```

Available templates:

- `ollama`: Ollama server environment
- `comfy-ui`: ComfyUI for AI image generation
- `webui-forge`: WebUI Forge for Stable Diffusion

After instance creation, start the server using `start-<template_name>` when connected. For example:

```
start-ollama
```

#### Mode Configuration

Choose between prototyping and production modes:

```
tnr create --mode <mode>
```

Available modes:
- `prototyping` (default): Development mode optimized for intermittent workloads
- `production`: Premium instance with maximum compatibility, stability, and reliability for production workloads

### Delete an Instance

```
tnr delete <instance_ID>
```

<Warning>
  This action permanently removes an instance and all associated data.
</Warning>

## Using instances

### Connect to an Instance

Use the `connect` command to access your instance. This wraps SSH, managing keys while automatically setting up everything you need to get started.

```
tnr connect <instance_ID>
```

Instances cannot be restarted once deleted, so always back up important data before destroying them. Use `tnr status` to see instance IDs (default `0`).

### Port Forwarding

Connect with port forwarding with the `-t` or `--tunnel` flag:

```
tnr connect <instance_ID> -t PORT1 -t PORT2
```

Features:

- Forward multiple ports using repeated `-t/--tunnel` flags
- Example: `tnr connect 0 -t 8000 -t 8080` forwards both ports 8000 and 8080
- Enables local access to remote web servers, APIs, and services

### Copy Files

Transfer files between local and remote instance with the `scp` command:

```
tnr scp <source_path> <destination_path>
```

You can transfer files in either direction, from your local machine to an instance, or from the instance to your local machine. You indicate the direction of transfer with the path format, shown below.

Path format:

- Remote: `instance_id:path` (e.g., `0:/home/user/data`)
- Local: Standard paths (e.g., `./data` or `/home/user/file.txt`)
- Must specify exactly one remote and one local path
- Paths can be either absolute or relative.

Examples:

```
# Upload to instance
tnr scp ./local_file.txt 0:/remote/path/

# Download from instance
tnr scp 0:/remote/file.txt ./local_path/
```

<Note>
  File transfers have a 60-second connection timeout. SSH key setup,
  compression, and `~/` expansion are handled automatically.
</Note>

## Instance Lifecycle

Instances cannot be modified after creation. To change configuration (GPU, vCPU, disk size, or mode), create a new instance with the desired settings and migrate your data before deleting the original.

### View Instance Status

List all instances and details including `instance_ID`, `IP Address`, `Disk Size`, `GPU Type`, `GPU Count`, `vCPU Count`, `RAM`, and `Template`:

```
tnr status
```

use the `--no-wait` flag to disable automatic monitoring for status updates
